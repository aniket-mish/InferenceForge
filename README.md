# InferenceForge

im building a llm inference platform to understand streaming, cancellation, observability, canary, autoscaling, GPU serving, distributed training, and safe rollout. im more focused on infra problems.
 